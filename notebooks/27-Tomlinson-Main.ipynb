{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is my GPU doing? <br /><small style=\"font-size: 1.2rem;color: #111111; font-weight: 300;\">Using PyNVML and NVDashboard to access GPU metrics.</small>\n",
    "\n",
    "**Author** - Jacob Tomlinson (NVIDIA)\n",
    "\n",
    "This notebook accompanies a talk of the same name presented at JupyterCon 2020.\n",
    "\n",
    "`pynvml` provides a Python interface to GPU management and monitoring functions. In this notebook we will use it to gather metrics about our GPUs, create plots and realtime dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pynvml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pynvml.nvmlInit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying system info\n",
    "\n",
    "You can query general system information with `pynvml` such as driver versions and the number of available GPUs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pynvml.nvmlSystemGetDriverVersion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pynvml.nvmlSystemGetNVMLVersion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_count = pynvml.nvmlDeviceGetCount()\n",
    "device_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying device info\n",
    "\n",
    "You can also query individual GPU devices for information and metrics.\n",
    "\n",
    "To query a device you need a handle which can be retrieved using the device index. This will be `[0, ..., n-1]` where `n` is the number of detected devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
    "handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pynvml.nvmlDeviceGetName(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"{pynvml.nvmlDeviceGetTemperature(handle, 0)}Â°C\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting data\n",
    "\n",
    "Now that we know how to query our GPU devices for metrics let's write a function which gathers a bunch of metrics in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_gpu(gpu_index):\n",
    "    handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_index)\n",
    "    return {\n",
    "        \"timestamp\": datetime.now(),\n",
    "        \"gpu_index\": gpu_index,\n",
    "        \"name\": pynvml.nvmlDeviceGetName(handle).decode(),\n",
    "        \"utilization\": pynvml.nvmlDeviceGetUtilizationRates(handle).gpu,\n",
    "        \"memory_used\": pynvml.nvmlDeviceGetMemoryInfo(handle).used,\n",
    "        \"memory_total\": pynvml.nvmlDeviceGetMemoryInfo(handle).total,\n",
    "        \"pcie_supported_generation\": pynvml.nvmlDeviceGetMaxPcieLinkGeneration(handle),\n",
    "        \"pcie_bandwidth_limit\": pynvml.nvmlDeviceGetMaxPcieLinkWidth(handle),\n",
    "        \"pcie_throughput_tx\": pynvml.nvmlDeviceGetPcieThroughput(handle, pynvml.NVML_PCIE_UTIL_TX_BYTES) * 1e3,\n",
    "        \"pcie_throughput_rx\": pynvml.nvmlDeviceGetPcieThroughput(handle, pynvml.NVML_PCIE_UTIL_RX_BYTES) * 1e3,\n",
    "        \"temperature\": pynvml.nvmlDeviceGetTemperature(handle, 0)\n",
    "    }\n",
    "\n",
    "get_data_for_gpu(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then write another function which gather metrics for all our GPUs and returns them in a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    return pd.DataFrame.from_dict([get_data_for_gpu(i) for i in range(device_count)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see a table of all our matrics that we queried about each device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting data over time\n",
    "\n",
    "To take this a step further let's query this information every 100ms and record it over time to create a time series DataFrame of our GPU usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout_seconds = 10\n",
    "samples_per_second = 10\n",
    "timeout_start = time.time()\n",
    "\n",
    "df = get_data()\n",
    "\n",
    "while time.time() < timeout_start + timeout_seconds:\n",
    "    time.sleep(1 / samples_per_second)\n",
    "    df = pd.concat([df, get_data()])\n",
    "\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "Now that we have some time series data let's plot it so we can see what our GPUs are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"gpu_index\").memory_used.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"gpu_index\").utilization.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real time plotting\n",
    "\n",
    "Seeing plots of our usage is really helpful, but what about real time monitoring. Let's use `bokeh` to create a live plot in our notebook showing real time GPU utilization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show, push_notebook, output_notebook\n",
    "from bokeh.models import ColumnDataSource\n",
    "from bokeh.palettes import Spectral6\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.transform import factor_cmap\n",
    "from random import shuffle\n",
    "\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to query our GPU names and IDs to give unique bar names for our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_names():\n",
    "    gpu_data = [get_data_for_gpu(i) for i in range(device_count)]\n",
    "    return [f\"{gpu['name']} ({gpu['gpu_index']})\" for gpu in gpu_data]\n",
    "\n",
    "gpus = get_gpu_names()\n",
    "gpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a function which uses our `get_data_for_gpu()` function from before but instead returns a list of GPU utilization which we will use to set the values on our plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_plot_data():\n",
    "    gpu_data = [get_data_for_gpu(i) for i in range(device_count)]\n",
    "    return [gpu['utilization'] for gpu in gpu_data]\n",
    "\n",
    "utilization = update_plot_data()\n",
    "utilization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this data we can create a `ColumnDataSource` and display the graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ColumnDataSource(data=dict(gpus=gpus, utilization=utilization))\n",
    "\n",
    "p = figure(x_range=gpus, plot_height=350, toolbar_location=None, title=\"GPU Utilization\")\n",
    "\n",
    "r = p.vbar(x='gpus', top='utilization', width=0.9, source=source,\n",
    "       line_color='white', fill_color=factor_cmap('gpus', palette=Spectral6, factors=gpus))\n",
    "\n",
    "p.y_range.start = 0\n",
    "p.y_range.end = 100\n",
    "\n",
    "target = show(p, notebook_handle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we need to poll `pynvml` every 100ms and update the data source with new values and tell `bokeh` to re-render the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    r.data_source.data[\"utilization\"] = update_plot_data()\n",
    "    push_notebook(handle=target)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
